{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection for AI Model\n",
    "\n",
    "In this notebook, we will collect datasets related to reasoning from Hugging Face and save them in a specified directory. We will use the `datasets` library from Hugging Face to download the datasets. The datasets we will download are:\n",
    "1. [nvidia/HelpSteer2](https://huggingface.co/datasets/nvidia/HelpSteer2)\n",
    "2. [Magpie-Align/Magpie-Reasoning-150K](https://huggingface.co/datasets/Magpie-Align/Magpie-Reasoning-150K)\n",
    "3. [KingNish/reasoning-base-20k](https://huggingface.co/datasets/KingNish/reasoning-base-20k)\n",
    "3. [SkunkworksAI/reasoning-0.01](https://huggingface.co/datasets/SkunkworksAI/reasoning-0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Configuration\n",
    "\n",
    "In this section, define the dataset name, save path, and output path for the dataset to be worked with.\n",
    "\n",
    "- **Dataset Name:** `Magpie-Align/Magpie-Reasoning-150K`\n",
    "- **Save Path:** `data/raw/Magpie-Align/Magpie-Reasoning-150K`\n",
    "- **Output Path:** `data/processed/Magpie-Align/Magpie-Reasoning-150K`\n",
    "\n",
    "These variables will be used in the subsequent steps for downloading and processing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Magpie-Align/Magpie-Reasoning-150K\"\n",
    "save_path = f\"data/raw/{dataset_name}\"\n",
    "output_path = f\"data/processed/{dataset_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection and Transformation\n",
    "\n",
    "In this section, we will use the `DataCollector` class to manage the dataset. The `DataCollector` class will be instantiated by passing the `dataset_name` and `save_path`. We will then call the `execute` method twice:\n",
    "\n",
    "1. First, with the argument `\"download\"` to download the dataset.\n",
    "2. Second, with the argument `\"convert_parquet\"` to transform the dataset into Parquet format and save it to the specified `output_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.data_collection import DataCollector\n",
    "    \n",
    "manager = DataCollector(dataset_name, save_path)\n",
    "\n",
    "manager.execute(\"download\")\n",
    "manager.execute(\"convert_parquet\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
